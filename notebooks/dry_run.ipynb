{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "565f59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91f24400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connectivity_matrix</th>\n",
       "      <th>compliance_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[16.2442166588418, -4.390589663678543, -4.392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[22.194443522542244, -7.184492662134119, -7.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[21.44865815819801, -6.467827160497426, -6.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[15.247634909853652, -3.931170890685161, -3.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[23.16273271145176, -5.511611078765939, -5.66...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 connectivity_matrix  \\\n",
       "0  [[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                   compliance_matrix  \n",
       "0  [[16.2442166588418, -4.390589663678543, -4.392...  \n",
       "1  [[22.194443522542244, -7.184492662134119, -7.1...  \n",
       "2  [[21.44865815819801, -6.467827160497426, -6.44...  \n",
       "3  [[15.247634909853652, -3.931170890685161, -3.9...  \n",
       "4  [[23.16273271145176, -5.511611078765939, -5.66...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1310, 2)\n"
     ]
    }
   ],
   "source": [
    "# Import data and important features for graph construction\n",
    "data = pd.read_pickle('../data/connectivity_compliance_matrices.pkl')\n",
    "\n",
    "# Get only rhos with value greater than 0.2 (rho = 0.3)\n",
    "data = data.rename(columns={'Ï': 'rho'})\n",
    "data = data[data['rho'] > 0.2]\n",
    "\n",
    "# Extract relevant features\n",
    "X = data[['connectivity_matrix', 'compliance_matrix']]\n",
    "X = X.reset_index(drop=True)\n",
    "display(X.head())\n",
    "print(f\"Shape of X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41b2a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59289b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge index:\n",
      "tensor([[ 0,  1],\n",
      "        [ 0,  4],\n",
      "        [ 1,  0],\n",
      "        [ 1,  7],\n",
      "        [ 2,  3],\n",
      "        [ 2, 10],\n",
      "        [ 3,  2],\n",
      "        [ 3,  4],\n",
      "        [ 4,  0],\n",
      "        [ 4,  3],\n",
      "        [ 4,  6],\n",
      "        [ 4, 10],\n",
      "        [ 6,  4],\n",
      "        [ 6,  6],\n",
      "        [ 7,  1],\n",
      "        [ 7,  7],\n",
      "        [10,  2],\n",
      "        [10,  4]])\n",
      "Compliance matrix:\n",
      "tensor([[16.2442, -4.3906, -4.3921,  0.0000,  0.0000,  0.0000],\n",
      "        [-4.3906, 16.2539, -4.3922,  0.0000,  0.0000,  0.0000],\n",
      "        [-4.3921, -4.3922, 16.2602,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, 38.9590,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 39.0762,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 39.0137]])\n"
     ]
    }
   ],
   "source": [
    "# Construct sample graph data consisting of edge index and node features (rho)\n",
    "sample = X.iloc[0]\n",
    "connectivity_matrix = sample['connectivity_matrix']\n",
    "compliance_matrix = sample['compliance_matrix']\n",
    "edge_index = np.array(np.nonzero(connectivity_matrix)).T\n",
    "display(sample['connectivity_matrix'])\n",
    "\n",
    "sample_data = Data(edge_index=torch.tensor(edge_index, dtype=torch.long), y=torch.tensor(compliance_matrix, dtype=torch.float32))\n",
    "print(f\"Edge index:\\n{sample_data.edge_index}\")\n",
    "print(f\"Compliance matrix:\\n{sample_data.y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed 1310 graph data objects.\n",
      "Sample graph data object:\n",
      "Data(x=[11, 1], edge_index=[2, 18], y=[36])\n"
     ]
    }
   ],
   "source": [
    "def construct_graph_data(row):\n",
    "    connectivity_matrix = row['connectivity_matrix']\n",
    "    compliance_matrix = row['compliance_matrix']\n",
    "    \n",
    "    edge_index = np.array(np.nonzero(connectivity_matrix)).T\n",
    "    num_nodes = connectivity_matrix.shape[0]\n",
    "    \n",
    "    # Create dummy node features\n",
    "    x = torch.ones((num_nodes, 1), dtype=torch.float32)\n",
    "\n",
    "    graph_data = Data(x=x,\n",
    "                      edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous(), \n",
    "                      y=torch.tensor(compliance_matrix.flatten(), dtype=torch.float32))\n",
    "    return graph_data\n",
    "\n",
    "# Apply the function to the entire DataFrame to create a list of graph data objects\n",
    "graph_data_list = X.apply(construct_graph_data, axis=1).tolist()\n",
    "print(f\"Constructed {len(graph_data_list)} graph data objects.\")\n",
    "print(f\"Sample graph data object:\\n{graph_data_list[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62a59a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 917\n",
      "Validation set size: 196\n",
      "Testing set size: 197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, foo = train_test_split(graph_data_list, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(foo, test_size=0.5, random_state=42)\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Testing set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac8f6750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SimpleGNN(\n",
      "  (conv1): GCNConv(1, 16)\n",
      "  (output_layer): Linear(in_features=16, out_features=36, bias=True)\n",
      ")\n",
      "Number of parameters: 644\n"
     ]
    }
   ],
   "source": [
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=16, output_dim=36):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(input_dim, hidden_dim)\n",
    "        self.output_layer = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Apply GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Global mean pooling to get graph-level representation\n",
    "        x = torch_geometric.nn.global_mean_pool(x, batch=None)\n",
    "        \n",
    "        # Output layer to predict 36 values (6x6 matrix flattened)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleGNN()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "274209fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 6800017767535.6973, Val Loss: 872.1540\n",
      "Epoch 10, Train Loss: 6800014876589.4004, Val Loss: 658.3445\n",
      "Epoch 20, Train Loss: 6800006167847.2148, Val Loss: 765.2523\n",
      "Epoch 30, Train Loss: 6799993106257.6445, Val Loss: 2530.5351\n",
      "Epoch 40, Train Loss: 6799975327952.6084, Val Loss: 8057.0421\n",
      "Epoch 50, Train Loss: 6799952469777.4209, Val Loss: 20167.6389\n",
      "Epoch 60, Train Loss: 6799924937706.7676, Val Loss: 42399.5029\n",
      "Epoch 70, Train Loss: 6799892772504.0244, Val Loss: 78999.8727\n",
      "Epoch 80, Train Loss: 6799855905838.5703, Val Loss: 134902.8015\n",
      "Epoch 90, Train Loss: 6799814453017.6094, Val Loss: 215730.2573\n"
     ]
    }
   ],
   "source": [
    "# Simple training loop\n",
    "def train_model(model, train_data, val_data, epochs=100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        total_train_loss = 0\n",
    "        for data in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out.squeeze(), data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_data)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_data:\n",
    "                out = model(data)\n",
    "                loss = criterion(out.squeeze(), data.y)\n",
    "                total_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_data)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        model.train()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses = train_model(model, train_data, val_data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "712d8350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted compliance matrix:\n",
      "tensor([[1248.,  948., -270.,   -0.,    0.,   -0.],\n",
      "        [ 948., 1296.,  369.,   -0.,   -0.,    0.],\n",
      "        [-261.,  374., 1241.,    0.,   -0.,    0.],\n",
      "        [  -0.,   -0.,    0., 1289.,   -0.,   -0.],\n",
      "        [   0.,   -0.,   -0.,   -0., 1287.,   -0.],\n",
      "        [  -0.,    0.,    0.,    0.,    0., 1277.]])\n",
      "Actual compliance matrix:\n",
      "tensor([[14.0232, -2.0633, -2.0688,  0.0000,  0.0000,  0.0000],\n",
      "        [-2.0633, 14.0003, -2.0616,  0.0000,  0.0000,  0.0000],\n",
      "        [-2.0688, -2.0616, 14.0295,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, 50.7279,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 50.8233,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 50.6560]]))\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[0]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(sample_test_data)\n",
    "    print(f\"Predicted compliance matrix:\\n{prediction.reshape(6,6).round()}\")\n",
    "    print(f\"Actual compliance matrix:\\n{sample_test_data.y.reshape(6,6)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c091c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem-277b-group-project (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
